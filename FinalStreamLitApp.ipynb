{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUi6bEVcEw6f"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5LYu8fLEEp0"
      },
      "outputs": [],
      "source": [
        "pip install streamlit-mic-recorder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IS1fSijR36U"
      },
      "outputs": [],
      "source": [
        "pip install SpeechRecognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPix99ROSIGW"
      },
      "outputs": [],
      "source": [
        "pip install gTTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JASR3YybTkQ3"
      },
      "outputs": [],
      "source": [
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZrXz7EKUdVA"
      },
      "outputs": [],
      "source": [
        "!pip install PyAudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ON5YFjkenPI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn1KfrGSEz1V",
        "outputId": "071e673b-d3ec-4fb5-aa15-89d7003ceddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.keras.models import load_model as model_loader\n",
        "import joblib\n",
        "from streamlit_mic_recorder import mic_recorder\n",
        "import speech_recognition as sr\n",
        "from gtts import gTTS\n",
        "import wave\n",
        "\n",
        "\n",
        "audio_file = None\n",
        "model = None\n",
        "\n",
        "def load_model():\n",
        "    try:\n",
        "        model = model_loader(\"/content/drive/MyDrive/CRNNSpoof_Model.h5\")\n",
        "        return model\n",
        "    except FileNotFoundError:\n",
        "        st.sidebar.error(\"Model file not found. Please make sure the file exists.\")\n",
        "        return None\n",
        "\n",
        "model = load_model()\n",
        "st.sidebar.success(\"Model loaded!\")\n",
        "\n",
        "\n",
        "st.title(\"Voice authentication ðŸŽµ:\")\n",
        "\n",
        "audio_file = st.file_uploader(\"Upload Audio\", type=[\"wav\",\"mp3\",\"flac\"])\n",
        "\n",
        "#start test\n",
        "\n",
        "\n",
        "def callback():\n",
        "    if st.session_state.my_recorder_output:\n",
        "        audio_bytes = st.session_state.my_recorder_output['bytes']\n",
        "        st.audio(audio_bytes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "audio_file_test = mic_recorder(key='my_recorder', callback=callback, format = 'wav')\n",
        "if audio_file_test is not None:\n",
        "    with wave.open('output.wav', 'wb') as wav_file:\n",
        "            audio_bytes = st.session_state.my_recorder_output['bytes']\n",
        "            wav_file.setnchannels(1) # Mono\n",
        "            wav_file.setsampwidth(2) # Sample width in bytes\n",
        "            wav_file.setframerate(44100) # Sample rate\n",
        "            wav_file.writeframes(audio_bytes)\n",
        "#end test\n",
        "#test start\n",
        "\n",
        "\n",
        "#end test\n",
        "st.sidebar.header(\"Play the audio\")\n",
        "st.sidebar.audio(audio_file)\n",
        "\n",
        "\n",
        "# Function to extract features from an audio file\n",
        "def extract_features(file_path, segment_length):\n",
        "    try:\n",
        "        # Load the audio file\n",
        "        y, sr = librosa.load(file_path)\n",
        "        # Calculate the number of segments based on the segment length and audio length\n",
        "        num_segments = int(np.ceil(len(y) / float(segment_length * sr)))\n",
        "        print(\"num_segments: \"+ str(num_segments))\n",
        "        # Initialize a list to store the features for this file\n",
        "        features = []\n",
        "\n",
        "        # Extract features for each segment\n",
        "        for i in range(num_segments):\n",
        "            # Calculate start and end frame for the current segment\n",
        "            start_frame = i * segment_length * sr\n",
        "            end_frame = min(len(y), (i + 1) * segment_length * sr)\n",
        "            # Extract audio for this segment\n",
        "            y_segment = y[start_frame:end_frame]\n",
        "\n",
        "            # Extract features\n",
        "            chroma_stft = np.mean(librosa.feature.chroma_stft(y=y_segment, sr=sr))\n",
        "            rms = np.mean(librosa.feature.rms(y=y_segment))\n",
        "            spec_cent = np.mean(librosa.feature.spectral_centroid(y=y_segment, sr=sr))\n",
        "            spec_bw = np.mean(librosa.feature.spectral_bandwidth(y=y_segment, sr=sr))\n",
        "            rolloff = np.mean(librosa.feature.spectral_rolloff(y=y_segment, sr=sr))\n",
        "            zcr = np.mean(librosa.feature.zero_crossing_rate(y_segment))\n",
        "            mfccs = librosa.feature.mfcc(y=y_segment, sr=sr)\n",
        "            mfccs_mean = np.mean(mfccs, axis=1)\n",
        "\n",
        "            # Append the extracted features to the list\n",
        "            features.append([chroma_stft, rms, spec_cent, spec_bw, rolloff, zcr, *mfccs_mean])\n",
        "\n",
        "        return np.array(features)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def make_prediction(features):\n",
        "    output = model.predict(features)\n",
        "    return output #test\n",
        "\n",
        "\n",
        "if st.sidebar.button(\"Test Audio\"):\n",
        "  if audio_file is not None or os.path.isfile(\"./output.wav\"):\n",
        "    if os.path.isfile(\"./output.wav\"):\n",
        "      audio_file = \"./output.wav\"\n",
        "      recognizer = sr.Recognizer()                #start\n",
        "      with sr.WavFile(\"./output.wav\") as source:\n",
        "        audio_data = recognizer.listen(source)\n",
        "        try:\n",
        "            text = recognizer.recognize_google(audio_data)\n",
        "            print(f\"Transcribed text: {text}\")\n",
        "\n",
        "            # Convert the transcribed text to AI voice\n",
        "            tts = gTTS(text=text, lang=\"en\")\n",
        "            ai_voice_file = \"ai_voice_output.wav\"\n",
        "            tts.save(ai_voice_file)\n",
        "            print(f\"AI voice saved to {ai_voice_file}\")\n",
        "            st.sidebar.header(\"Real audio\")\n",
        "            st.sidebar.audio(\"./output.wav\")\n",
        "            st.sidebar.header(\"Fake audio\")\n",
        "            st.sidebar.audio(ai_voice_file)\n",
        "\n",
        "            # Optionally play the AI voice\n",
        "            # os.system(f\"start {ai_voice_file}\")\n",
        "\n",
        "        except sr.UnknownValueError:\n",
        "            print(\"Could not understand the audio\")\n",
        "        except sr.RequestError as e:\n",
        "            print(f\"Could not request results; {e}\")    #end\n",
        "\n",
        "    st.sidebar.success(\"Processing audio...\")\n",
        "\n",
        "    features = extract_features(audio_file, segment_length=1)\n",
        "    X = pd.DataFrame(features, columns = ['chroma_stft', 'rms', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20'])\n",
        "    scaler = joblib.load(\"/content/drive/MyDrive/CRNNSpoof_scale.joblib\")\n",
        "\n",
        "    X_test_scaled = scaler.transform(features.reshape(features.shape[0], -1))\n",
        "    X_test_scaled = X_test_scaled.reshape(features.shape)\n",
        "\n",
        "    X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "\n",
        "    # Use the model to make predictions on the dataset\n",
        "    st.write(\"Making predictions with the model...\")\n",
        "\n",
        "    if features is not None:\n",
        "        prediction_result = make_prediction(X_test_scaled)\n",
        "\n",
        "    if np.average(prediction_result) <= 0.3:\n",
        "      st.write(\"Prediction: Fake \")\n",
        "    else:\n",
        "      st.write(\"Prediction: Real \")\n",
        "    if os.path.isfile(\"./output.wav\"):\n",
        "      os.remove(\"./output.wav\")\n",
        "  else:\n",
        "    st.sidebar.warning(\"No Model\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLvhEVW6E6II"
      },
      "outputs": [],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukboCngRFpoH",
        "outputId": "7117f7a6-58c2-4899-9e9c-c307458d8d4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Password/Enpoint IP for localtunnel is: 35.229.199.218\n"
          ]
        }
      ],
      "source": [
        "import urllib\n",
        "\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DK8joaBE9Ot"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "15rBWVT5FCAA"
      },
      "outputs": [],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}